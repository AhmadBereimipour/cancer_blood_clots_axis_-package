{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Linear Regression\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(X_train, y_train)\n",
    "linear_regression_predictions = linear_regression_model.predict(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "logistic_regression_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Decision Trees\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "decision_tree_predictions = decision_tree_model.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "random_forest_predictions = random_forest_model.predict(X_test)\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# k-Nearest Neighbors (k-NN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Naive Bayes\n",
    "naive_bayes_model = GaussianNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "naive_bayes_predictions = naive_bayes_model.predict(X_test)\n",
    "\n",
    "# Gradient Boosting Machines (GBM)\n",
    "gbm_model = GradientBoostingClassifier()\n",
    "gbm_model.fit(X_train, y_train)\n",
    "gbm_predictions = gbm_model.predict(X_test)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "adaboost_predictions = adaboost_model.predict(X_test)\n",
    "\n",
    "# Principal Component Analysis (PCA)\n",
    "pca = PCA(n_components=2)  # Adjust the number of components as needed\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# K-Means Clustering\n",
    "kmeans_model = KMeans(n_clusters=3)  # Adjust the number of clusters as needed\n",
    "kmeans_model.fit(X_train)\n",
    "kmeans_cluster_labels = kmeans_model.predict(X_test)\n",
    "\n",
    "# Hierarchical Clustering\n",
    "hierarchical_model = AgglomerativeClustering(n_clusters=3)  # Adjust the number of clusters as needed\n",
    "hierarchical_cluster_labels = hierarchical_model.fit_predict(X)\n",
    "\n",
    "# Gaussian Mixture Models (GMM)\n",
    "gmm_model = GaussianMixture(n_components=3)  # Adjust the number of components as needed\n",
    "gmm_model.fit(X_train)\n",
    "gmm_cluster_labels = gmm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace X_train, y_train, X_test, and y_test with your actual training and test data. Adjust hyperparameters such as the number of components, clusters, etc., based on your specific requirements and the characteristics of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define a dictionary to store scores for each model\n",
    "scores = {}\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': linear_regression_model,\n",
    "    'Logistic Regression': logistic_regression_model,\n",
    "    'Decision Tree': decision_tree_model,\n",
    "    'Random Forest': random_forest_model,\n",
    "    'SVM': svm_model,\n",
    "    'k-NN': knn_model,\n",
    "    'Naive Bayes': naive_bayes_model,\n",
    "    'Gradient Boosting': gbm_model,\n",
    "    'AdaBoost': adaboost_model\n",
    "}\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {'accuracy': accuracy_score,\n",
    "           'precision': precision_score,\n",
    "           'recall': recall_score,\n",
    "           'f1': f1_score}\n",
    "\n",
    "# Iterate over models\n",
    "for name, model in models.items():\n",
    "    scores[name] = {}\n",
    "    for metric_name, metric_func in scoring.items():\n",
    "        scores[name][metric_name] = cross_val_score(model, X_train, y_train, cv=5, scoring=metric_func).mean()\n",
    "\n",
    "# Display scores\n",
    "for name, metrics in scores.items():\n",
    "    print(f\"\\n{name} Scores:\")\n",
    "    for metric_name, score in metrics.items():\n",
    "        print(f\"{metric_name}: {score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
